# Hand Gesture Recognition

A Python project for **hand gesture recognition** using **OpenCV**, **MediaPipe**, and **scikit-learn**.  
This project allows you to:  
1. Collect hand gesture images via webcam.  
2. Process images into normalized landmarks.  
3. Train a Random Forest classifier.  
4. Run inference on new hand gestures in real-time.

---

## ğŸ“ Project Structure

```

â”œâ”€â”€ collect\_imgs.py        # Capture hand gesture images from webcam
â”œâ”€â”€ create\_dataset.py      # Extract hand landmarks and save dataset
â”œâ”€â”€ train\_classifier.py    # Train Random Forest classifier
â”œâ”€â”€ inference\_classifier.py # Run real-time gesture recognition
â”œâ”€â”€ data/                  # Folder for storing gesture images
â”œâ”€â”€ data.pickle            # Pickled dataset of hand landmarks
â”œâ”€â”€ model.p                # Trained Random Forest model
â””â”€â”€ requirements.txt       # Python dependencies

````

---

## âš¡ Requirements

- Python 3.10+
- Packages listed in `requirements.txt`:

```text
opencv-python==4.7.0.68
mediapipe==0.10.21
scikit-learn==1.2.0
numpy>=1.24
````

Install dependencies using:

```bash
pip install -r requirements.txt
```

---

## ğŸ–ï¸ Usage

### 1. Collect Images

Run the script to capture hand gesture images:

```bash
python collect_imgs.py
```

* Images are saved in `./data/<class_number>/` folders.
* Press **Q** to start capturing after positioning your hand.
* Each class collects **100 images** by default.

---

### 2. Create Dataset

Extract hand landmarks and save to a pickle file:

```bash
python create_dataset.py
```

* This creates `data.pickle` containing `data` (landmarks) and `labels`.

---

### 3. Train Classifier

Train a **Random Forest** classifier:

```bash
python train_classifier.py
```

* Trains on the dataset from `data.pickle`.
* Saves trained model to `model.p`.
* Prints accuracy on the test set.

---

### 4. Inference (Real-Time Recognition)

Run real-time gesture recognition:

```bash
python inference_classifier.py
```

* Detects hand gestures via webcam.
* Uses the trained `model.p` to predict the gesture class.

---

## ğŸ”§ Customization

* **Number of classes**: Change `number_of_classes` in `collect_imgs.py`.
* **Images per class**: Adjust `dataset_size` in `collect_imgs.py`.
* **Model parameters**: Edit `n_estimators` or `max_depth` in `train_classifier.py`.

---

## âš¡ Notes

* Ensure good lighting and a plain background for better hand detection.
* The classifier works best with **one hand per image**.
* All scripts assume the folder `data/` exists (it will be created automatically).

---

## ğŸ“„ License

This project is **open-source**. Feel free to use, modify, or share.

---

## ğŸ“Œ Author

 Anna-Simmi

```


